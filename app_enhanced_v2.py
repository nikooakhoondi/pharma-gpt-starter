# app_enhanced_v2.py â€” Supabase-only: Pivot + Filter/Table + GPT Chat (fixed indentation)
from typing import Optional
import os, json
import pandas as pd
import streamlit as st
import streamlit_authenticator as stauth
from supabase import create_client, Client
from openai import OpenAI

# ---------------------------- Page config ----------------------------
st.set_page_config(page_title="Pharma-GPT (Supabase)", layout="wide")

# ---------------------------- Auth helpers ----------------------------
def do_login(authenticator):
    try:
        return authenticator.login(location="main")
    except TypeError:
        pass
    try:
        return authenticator.login("Login", "main")
    except TypeError:
        return authenticator.login("Login", location="main")

def _build_authenticator_from_secrets():
    AUTH = st.secrets.get("auth", {})
    cookie_name = str(AUTH.get("cookie_name", "pharma_gpt_auth"))
    cookie_key  = str(AUTH.get("cookie_key", "change-me"))
    cookie_days = int(AUTH.get("cookie_expiry_days", 7))

    users = {}
    creds_in = AUTH.get("credentials", {}).get("usernames", {})
    for uname, info in creds_in.items():
        users[str(uname)] = {
            "name":     str(info.get("name", "")),
            "email":    str(info.get("email", "")),
            "password": str(info.get("password", "")),
        }

    if not users:
        st.error("No users found in secrets. Add them under [auth] â†’ [auth.credentials.usernames.*] in `.streamlit/secrets.toml`.")
        st.stop()

    return stauth.Authenticate({"usernames": users}, cookie_name, cookie_key, cookie_days)

# ---------------------------- Supabase ----------------------------
@st.cache_resource
def get_supabase() -> Optional[Client]:
    url = st.secrets.get("SUPABASE_URL")
    key = st.secrets.get("SUPABASE_KEY")
    if not url or not key:
        st.error("Missing SUPABASE_URL / SUPABASE_KEY in Streamlit Secrets.")
        return None
    return create_client(url, key)

sb = get_supabase()
if sb is None:
    st.stop()

# ---------------------------- Cached OpenAI client ----------------------------
@st.cache_resource
def get_openai_client():
    key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not key:
        return None
    return OpenAI(api_key=key)

TABLE = "Amarname_sheet1"  # keep exactly as user requested

with st.expander("ğŸ” Data health check"):
    @st.cache_data(ttl=120)
    def db_total_rows():
        try:
            r = sb.table(TABLE).select("*", count="exact", head=True).execute()
            return r.count or 0
        except Exception:
            return None

    @st.cache_data(ttl=300)
    def count_by_year():
        counts = {}
        start = 0
        trans = str.maketrans("Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹", "0123456789")
        while True:
            r = sb.table(TABLE).select('"Ø³Ø§Ù„"').range(start, start + 999).execute()
            rows = r.data or []
            if not rows:
                break
            for rec in rows:
                y = rec.get("Ø³Ø§Ù„")
                if y is None:
                    continue
                y = str(y).translate(trans).strip()
                # keep only digits
                import re
                m = re.search(r"\d+", y)
                if m:
                    yy = int(m.group(0))
                    counts[yy] = counts.get(yy, 0) + 1
            start += len(rows)
        # sort by numeric year
        return dict(sorted(counts.items(), key=lambda x: x[0]))

    st.write("Total rows:", db_total_rows())
    st.write("Rows by Ø³Ø§Ù„:", count_by_year())


# ---------------------------- Shared constants ----------------------------
ALLOWED_DIMS = [
    "Ø³Ø§Ù„","Ú©Ø¯ Ú˜Ù†Ø±ÛŒÚ©","Ù†Ø§Ù… Ú˜Ù†Ø±ÛŒÚ©","Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ","Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ ÙØ±Ø¢ÙˆØ±Ø¯Ù‡",
    "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡","ØªÙˆÙ„ÛŒØ¯ÛŒ/ÙˆØ§Ø±Ø¯Ø§ØªÛŒ","route","dosage form","atc code","Anatomical",
]
ALLOWED_METRICS = ["Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ", "Ù‚ÛŒÙ…Øª", "ØªØ¹Ø¯Ø§Ø¯ ØªØ§Ù…ÛŒÙ† Ø´Ø¯Ù‡"]

COLS = {
    "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ",
    "Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯": "Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ ÙØ±Ø¢ÙˆØ±Ø¯Ù‡",
    "Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": "dosage form",
    "Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù": "route",
    "Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡": "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡",
    "Ø³Ø§Ù„": "Ø³Ø§Ù„",
    "ATC code": "atc code",
    "ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„": "ØªÙˆÙ„ÛŒØ¯ÛŒ/ÙˆØ§Ø±Ø¯Ø§ØªÛŒ",
    # for sorting/visible extras
    "Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ": "Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ",
    "ØªØ¹Ø¯Ø§Ø¯ ØªØ§Ù…ÛŒÙ† Ø´Ø¯Ù‡": "ØªØ¹Ø¯Ø§Ø¯ ØªØ§Ù…ÛŒÙ† Ø´Ø¯Ù‡",
    "Ù‚ÛŒÙ…Øª": "Ù‚ÛŒÙ…Øª",
}

SYNONYMS = {
    "Ø´Ø±Ú©Øª": "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡",
    "ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡": "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡",
    "Ú˜Ù†Ø±ÛŒÚ©": "Ù†Ø§Ù… Ú˜Ù†Ø±ÛŒÚ©",
    "Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ": "Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ ÙØ±Ø¢ÙˆØ±Ø¯Ù‡",
    "Ú©Ø¯": "Ú©Ø¯ Ú˜Ù†Ø±ÛŒÚ©",
    "Ø³Ø§Ù„ Ø´Ù…Ø³ÛŒ": "Ø³Ø§Ù„",
    "Ù…Ø³ÛŒØ±": "route",
    "Ø´Ú©Ù„": "dosage form",
    "Ø§Ø±Ø²Ø´": "Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ",
    "Ù‚ÛŒÙ…Øª ÙˆØ§Ø­Ø¯": "Ù‚ÛŒÙ…Øª",
    "ØªØ¹Ø¯Ø§Ø¯": "ØªØ¹Ø¯Ø§Ø¯ ØªØ§Ù…ÛŒÙ† Ø´Ø¯Ù‡",
    "ATC": "atc code",
}

# ---------------------------- Cached helpers (TOP-LEVEL) ----------------------------
@st.cache_data(ttl=300)
def run_pivot_rpc(dim1: str, dim2: str, metric: str, y1: int, y2: int) -> pd.DataFrame:
    try:
        res = sb.rpc(
            "pivot_2d_numeric",
            {"dim1": dim1, "dim2": dim2, "metric": metric,
             "year_from": int(y1), "year_to": int(y2)}
        ).execute()
        return pd.DataFrame(res.data or [])
    except Exception as e:
        st.error(f"Supabase RPC failed: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=1800)
def load_all_uniques(page_size: int = 5000):
    """
    Load ALL distinct values for ALL filter columns in ONE scan over the table.
    Much faster and complete.
    """
    cols = {
        "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ",
        "Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯": "Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ ÙØ±Ø¢ÙˆØ±Ø¯Ù‡",
        "Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": "dosage form",
        "Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù": "route",
        "Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡": "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡",
        "Ø³Ø§Ù„": "Ø³Ø§Ù„",
        "ATC code": "atc code",
        "ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„": "ØªÙˆÙ„ÛŒØ¯ÛŒ/ÙˆØ§Ø±Ø¯Ø§ØªÛŒ",
    }

    def q(c: str) -> str:
        try:
            simple = c.isascii() and c.replace("_", "").isalnum()
        except Exception:
            simple = False
        return c if simple else f'"{c}"'

    select_list = ",".join([q(v) for v in cols.values()])

    sets = {k: set() for k in cols.keys()}
    start = 0
    safety_pages = 0

    while True:
        end = start + page_size - 1
        r = sb.table(TABLE).select(select_list).range(start, end).execute()
        rows = r.data or []
        if not rows:
            break

        for rec in rows:
            for nice, actual in cols.items():
                v = rec.get(actual)
                if v is None:
                    continue
                if isinstance(v, str) and not v.strip():
                    continue
                sets[nice].add(v)

        got = len(rows)
        start += got
        safety_pages += 1
        if got < page_size or safety_pages > 5000:
            break

    out = {}
    for k, s in sets.items():
        try:
            out[k] = sorted(s)
        except TypeError:
            out[k] = sorted({str(v) for v in s})
    return out

@st.cache_data(ttl=600)
def query_with_filters(
    mols, brands, forms, routes, provs, years, atc_exact, atc_prefix, prod_type,
    sort_by, descending, limit_rows
):
    q = sb.table(TABLE).select("*")

    if mols:      q = q.in_(COLS["Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ"], mols)
    if brands:    q = q.in_(COLS["Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯"], brands)
    if forms:     q = q.in_(COLS["Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ"], forms)
    if routes:    q = q.in_(COLS["Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù"], routes)
    if provs:     q = q.in_(COLS["Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡"], provs)
    if years:     q = q.in_(COLS["Ø³Ø§Ù„"], years)
    if prod_type: q = q.in_(COLS["ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„"], prod_type)

    # ATC: exact first; else prefix
    if atc_exact:
        q = q.in_(COLS["ATC code"], atc_exact)
    elif atc_prefix and atc_prefix.strip():
        try:
            q = q.ilike(COLS["ATC code"], atc_prefix.strip() + "%")
        except Exception:
            q = q.like(COLS["ATC code"], atc_prefix.strip() + "%")

    # Avoid server-side order() on non-ASCII names; sort client-side instead
    try:
        res = q.limit(int(limit_rows)).execute()
    except Exception as e:
        st.error(f"Supabase query failed: {e}")
        return pd.DataFrame()

    df = pd.DataFrame(res.data or [])

    # Normalize year values (handles Persian digits / whitespace)
    if not df.empty and "Ø³Ø§Ù„" in df.columns:
        trans = str.maketrans("Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹", "0123456789")
        df["Ø³Ø§Ù„"] = (
            df["Ø³Ø§Ù„"].astype(str).str.translate(trans).str.strip()
            .str.extract(r"(\d+)")[0].astype("Int64")
        )

    if not df.empty and sort_by in df.columns:
        df = df.sort_values(sort_by, ascending=not descending, kind="mergesort")

    return df


@st.cache_data(ttl=600)
def get_facet_options(target_nice: str, selections: dict, page_size: int = 5000):
    """
    Return options for ONE filter (target_nice) limited by all *other* selected filters.
    Example: options for 'Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡' when 'Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ' = ['Metronidazole'].
    """
    # Map nice name â†’ actual column
    COLS_LOCAL = {
        "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ",
        "Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯": "Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ ÙØ±Ø¢ÙˆØ±Ø¯Ù‡",
        "Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": "dosage form",
        "Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù": "route",
        "Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡": "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡",
        "Ø³Ø§Ù„": "Ø³Ø§Ù„",
        "ATC code": "atc code",
        "ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„": "ØªÙˆÙ„ÛŒØ¯ÛŒ/ÙˆØ§Ø±Ø¯Ø§ØªÛŒ",
    }
    target_col = COLS_LOCAL[target_nice]

    # build query applying all filters EXCEPT the target facet itself
    q = sb.table(TABLE).select(f'"{target_col}"')

    # Apply multi-select filters (exclude target)
    for nice, actual in COLS_LOCAL.items():
        if nice == target_nice:
            continue
        vals = selections.get(nice) or []
        if vals:
            q = q.in_(actual, vals)

    # ATC exact/prefix (if present in selections)
    atc_exact = selections.get("ATC code") or []
    atc_prefix = (selections.get("ATC prefix") or "").strip()
    if atc_exact:
        q = q.in_(COLS_LOCAL["ATC code"], atc_exact)
    elif atc_prefix:
        try:
            q = q.ilike(COLS_LOCAL["ATC code"], atc_prefix + "%")
        except Exception:
            q = q.like(COLS_LOCAL["ATC code"], atc_prefix + "%")

    # page through and collect distinct values client-side
    opts = set()
    start = 0
    while True:
        end = start + page_size - 1
        r = q.range(start, end).execute()
        rows = r.data or []
        if not rows:
            break
        for rec in rows:
            v = rec.get(target_col)
            if v is None:
                continue
            if isinstance(v, str) and not v.strip():
                continue
            opts.add(v)
        got = len(rows)
        start += got
        if got < page_size:
            break

    try:
        return sorted(opts)
    except TypeError:
        return sorted({str(v) for v in opts})


# ---------------------------- Preface ----------------------------
st.title("ğŸ’Š Pharma-GPT")
st.caption("Pivot like Excel â€” or ask in natural language. Results come from your Supabase table: Amarname_sheet1.")

with st.expander("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø³Ø±ÛŒØ¹ / Quick Start", expanded=True):
    st.markdown(
        """
**Ø¯Ùˆ Ù…Ø³ÛŒØ± Ø¯Ø§Ø±ÛŒØ¯:**
1) **Pivot**: Ø¯Ùˆ Ø¨ÙØ¹Ø¯ + ÛŒÚ© Ù…ØªØ±ÛŒÚ© Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¬Ù…Ø¹â€ŒÙ‡Ø§ Ø±Ø§ Ø±ÙˆÛŒ Ú©Ù„ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø¨ÛŒÙ†ÛŒØ¯.  
2) **ÙÛŒÙ„ØªØ±/Ø¬Ø¯ÙˆÙ„**: Ø¨Ø§ Ø¬Ø¹Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆØŒ Ø¯Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ **Ù…ÙˆÙ„Ú©ÙˆÙ„ØŒ Ø¨Ø±Ù†Ø¯ØŒ Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒØŒ Ù…Ø³ÛŒØ± Ù…ØµØ±ÙØŒ ØªØ§Ù…ÛŒÙ†â€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ Ø³Ø§Ù„ØŒ ATC ÛŒØ§ ØªÙˆÙ„ÛŒØ¯ÛŒ/ÙˆØ§Ø±Ø¯Ø§ØªÛŒ** ÙÛŒÙ„ØªØ± Ùˆ Ù…Ø±ØªØ¨ Ú©Ù†ÛŒØ¯ Ùˆ CSV Ø¨Ú¯ÛŒØ±ÛŒØ¯.  

**Chat**: Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ/Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹: Â«Ø³Ù‡Ù… Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ Ù‡Ø± Ø´Ø±Ú©Øª Ø¯Ø± Û±Û´Û°Û°â€“Û±Û´Û°Û²ØŸÂ») ØªØ§ Ø®Ø±ÙˆØ¬ÛŒ Ø¬Ø¯ÙˆÙ„/Ú†Ø§Ø±Øª Ø¨Ú¯ÛŒØ±ÛŒØ¯.  
**Ù†Ú©ØªÙ‡ ATC**: Ù‡Ù… Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ù‚ÛŒÙ‚ Ø¯Ø§Ø±ÛŒØ¯ØŒ Ù‡Ù… Ù¾ÛŒØ´ÙˆÙ†Ø¯ (Ù…Ø«Ù„ `N06A%`).  
"""
    )

# ---------------------------- Auth gate ----------------------------
authenticator = _build_authenticator_from_secrets()
name, auth_status, username = do_login(authenticator)
if not auth_status:
    if auth_status is False:
        st.error("Incorrect username or password")
    else:
        st.info("Please log in to continue.")
    st.stop()
else:
    try:
        authenticator.logout("Logout", location="sidebar")
    except TypeError:
        authenticator.logout("Logout", "sidebar")

# ---------------------------- Tabs ----------------------------
tab_table, tab_chat = st.tabs(["ğŸ“‹ Filter/Table", "ğŸ’¬ Chat"])

# ============================ FILTER / TABLE ============================
with tab_table:
    st.subheader("ÙÛŒÙ„ØªØ±Ù‡Ø§")

    with st.spinner("Loading filter lists..."):
        UNI = load_all_uniques()

    # ---- Debounced filter form ----
    with st.form("filters_form", clear_on_submit=False):
        # current selections (empty lists if nothing yet)
        current = {
            "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": st.session_state.get("mols", []),
            "Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯": st.session_state.get("brands", []),
            "Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ": st.session_state.get("forms", []),
            "Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù": st.session_state.get("routes", []),
            "Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡": st.session_state.get("provs", []),
            "Ø³Ø§Ù„": st.session_state.get("years", []),
            "ATC code": st.session_state.get("atc_exact", []),
            "ATC prefix": st.session_state.get("atc_prefix", ""),
            "ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„": st.session_state.get("prod_type", []),
        }

        c1, c2 = st.columns(2)
        with c1:
            mols = st.multiselect(
                "Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ",
                options=get_facet_options("Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ", current),
                key="mols"
            )
            brands = st.multiselect(
                "Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯",
                options=get_facet_options("Ù†Ø§Ù… Ø¨Ø±Ù†Ø¯", current),
                key="brands"
            )
            forms = st.multiselect(
                "Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ",
                options=get_facet_options("Ø´Ú©Ù„ Ø¯Ø§Ø±ÙˆÛŒÛŒ", current),
                key="forms"
            )
            routes = st.multiselect(
                "Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù",
                options=get_facet_options("Ø·Ø±ÛŒÙ‚Ù‡ Ù…ØµØ±Ù", current),
                key="routes"
            )
        with c2:
            provs = st.multiselect(
                "Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡",
                options=get_facet_options("Ù†Ø§Ù… ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡", current),
                key="provs"
            )
            years = st.multiselect(
                "Ø³Ø§Ù„",
                options=get_facet_options("Ø³Ø§Ù„", current),
                key="years"
            )
            atc_exact = st.multiselect(
                "ATC code (Exact)",
                options=get_facet_options("ATC code", current),
                key="atc_exact"
            )
            atc_prefix = st.text_input(
                "ÙÛŒÙ„ØªØ± ATC Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾ÛŒØ´ÙˆÙ†Ø¯ (Ù…Ø«Ù„ N06A)",
                value=st.session_state.get("atc_prefix", ""),
                key="atc_prefix"
            )

        prod_type = st.multiselect(
            "ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„",
            options=get_facet_options("ÙˆØ§Ø±Ø¯Ø§ØªÛŒ/ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø®Ù„", current),
            key="prod_type"
        )

        st.markdown("---")
        colA, colB, colC = st.columns(3)
        with colA:
            sort_by = st.selectbox(
                "Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³",
                options=[COLS["Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ"], COLS["ØªØ¹Ø¯Ø§Ø¯ ØªØ§Ù…ÛŒÙ† Ø´Ø¯Ù‡"], COLS["Ù‚ÛŒÙ…Øª"], COLS["Ø³Ø§Ù„"]],
                format_func=lambda c: [k for k, v in COLS.items() if v == c][0]
            )
        with colB:
            descending = st.toggle("Ù†Ø²ÙˆÙ„ÛŒ", value=True)
        with colC:
            limit_rows = st.number_input("Ø­Ø¯Ø§Ú©Ø«Ø± Ø±Ø¯ÛŒÙ", value=20000, min_value=1000, step=1000)

        # âœ… Submit button MUST be inside this form block
        applied = st.form_submit_button("Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±Ù‡Ø§")


    # ---- First-load & diffing logic (outside the form) ----
    if "filters_last" not in st.session_state:
        st.session_state.filters_last = None

    signature = (
        tuple(sorted(mols)), tuple(sorted(brands)), tuple(sorted(forms)), tuple(sorted(routes)),
        tuple(sorted(provs)), tuple(sorted(years)), tuple(sorted(atc_exact)),
        (atc_prefix or "").strip(), tuple(sorted(prod_type)), sort_by, bool(descending), int(limit_rows)
    )

    should_query = applied or (st.session_state.filters_last is None) or (st.session_state.filters_last != signature)

    if should_query:
        df = query_with_filters(
            mols, brands, forms, routes, provs, years, atc_exact, atc_prefix, prod_type,
            sort_by, descending, limit_rows
        )
        st.session_state.filters_last = signature
        st.session_state.filtered_df = df
    else:
        df = st.session_state.get("filtered_df", pd.DataFrame())

    st.markdown("### Ø®Ø±ÙˆØ¬ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡")
    st.dataframe(df, use_container_width=True, hide_index=True)
    if not df.empty:
        st.download_button(
            label="Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV",
            data=df.to_csv(index=False).encode("utf-8-sig"),
            file_name="filtered.csv",
            mime="text/csv",
            key="download_csv_filtered"
        )

    # ---- Pivot-like chart from filtered rows (unchanged behaviour) ----
    st.markdown("---")
    st.subheader("Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡")

    agg_dims_all = [
        "Ø³Ø§Ù„","Ú©Ø¯ Ú˜Ù†Ø±ÛŒÚ©","Ù†Ø§Ù… Ú˜Ù†Ø±ÛŒÚ©","Ù…ÙˆÙ„Ú©ÙˆÙ„ Ø¯Ø§Ø±ÙˆÛŒÛŒ","Ù†Ø§Ù… ØªØ¬Ø§Ø±ÛŒ ÙØ±Ø¢ÙˆØ±Ø¯Ù‡",
        "Ø´Ø±Ú©Øª ØªØ§Ù…ÛŒÙ† Ú©Ù†Ù†Ø¯Ù‡","ØªÙˆÙ„ÛŒØ¯ÛŒ/ÙˆØ§Ø±Ø¯Ø§ØªÛŒ","route","dosage form","atc code","Anatomical",
    ]
    agg_metric_all = ["Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ", "Ù‚ÛŒÙ…Øª", "ØªØ¹Ø¯Ø§Ø¯ ØªØ§Ù…ÛŒÙ† Ø´Ø¯Ù‡"]

    cc1, cc2, cc3 = st.columns(3)
    with cc1:
        agg_dim1 = st.selectbox("Ø¨Ø¹Ø¯ Ø§ÙˆÙ„ (Dimension 1)", agg_dims_all, index=0, key="agg_dim1")
    with cc2:
        agg_dim2_sel = st.selectbox("Ø¨Ø¹Ø¯ Ø¯ÙˆÙ… (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)", ["â€” Ù‡ÛŒÚ† â€”"] + agg_dims_all, index=0, key="agg_dim2")
        agg_dim2 = None if agg_dim2_sel == "â€” Ù‡ÛŒÚ† â€”" else agg_dim2_sel
    with cc3:
        agg_metric = st.selectbox("Ù…ØªØ±ÛŒÚ© (Ù…Ø¬Ù…ÙˆØ¹)", agg_metric_all, index=0, key="agg_metric")

    if df.empty:
        st.info("Ù¾Ø³ Ø§Ø² Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±Ù‡Ø§ØŒ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¬Ù…ÛŒØ¹ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    else:
        missing = [c for c in [agg_dim1, agg_dim2, agg_metric] if c and c not in df.columns]
        if missing:
            st.warning(f"Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯: {missing}")
        else:
            group_cols = [c for c in [agg_dim1, agg_dim2] if c]
            try:
                g = df.groupby(group_cols, dropna=False)[agg_metric].sum().reset_index()
            except Exception:
                tmp = df.copy()
                for c in group_cols:
                    tmp[c] = tmp[c].astype(str)
                g = tmp.groupby(group_cols, dropna=False)[agg_metric].sum().reset_index()

            label = g[agg_dim1].astype(str).fillna("")
            if agg_dim2:
                label = label + " â€” " + g[agg_dim2].astype(str).fillna("")
            chart_df = pd.DataFrame({"label": label, "total_value": g[agg_metric]}).sort_values("total_value", ascending=False)
            st.bar_chart(chart_df.set_index("label")[["total_value"]])
            st.caption(f"Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ ØªØ¬Ù…ÛŒØ¹â€ŒØ´Ø¯Ù‡: {len(g)}  |  Ø³ØªÙˆÙ† ØªØ¬Ù…ÛŒØ¹: {agg_metric}")


    
# ============================ GPT DATA CHAT ============================
with tab_chat:
    st.subheader("Ú¯ÙØªÚ¯Ùˆ Ø¨Ø§ Ø¯ÛŒØªØ§Ø¨ÛŒØ³")

    client = get_openai_client()
    if not client:
        st.warning("OpenAI API key not found â€” data chat is disabled.")
    else:
        # Initialize chat history
        if "data_chat" not in st.session_state:
            st.session_state.data_chat = []

        # Render chat history
        for msg in st.session_state.data_chat:
            role = msg.get("role", "assistant")
            content = msg.get("content", "")
            try:
                st.chat_message(role).write(content)
            except Exception:
                st.chat_message("assistant").write("âš ï¸ Ù¾ÛŒØ§Ù… Ù‚Ø¨Ù„ÛŒ Ù‚Ø§Ø¨Ù„ Ù†Ù…Ø§ÛŒØ´ Ù†ÛŒØ³Øª.")

        # User input
        user_q = st.chat_input("Ù…Ø«Ù„Ø§Ù‹: Ø³Ù‡Ù… Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ Ù‡Ø± Ø´Ø±Ú©Øª Ø¯Ø± Ø³Ø§Ù„â€ŒÙ‡Ø§ÛŒ Û±Û´Û°Û° ØªØ§ Û±Û´Û°Û²ØŸ", key="data_chat_input")
        if user_q:
            st.chat_message("user").write(user_q)
            st.session_state.data_chat.append({"role": "user", "content": user_q})

            # Build GPT system prompt
            guide = {"allowed_dims": ALLOWED_DIMS, "allowed_metrics": ALLOWED_METRICS, "allowed_filters": ALLOWED_DIMS}
            system_prompt = f"""
You are a planner that outputs ONLY compact JSON (no prose). You control a data tool with:
- pivot(dim1, dim2, metric, year_from, year_to)
- rows(filters, limit)

Rules:
- Use Persian or English inputs.
- If the user asks for shares or totals by categories, use "pivot".
- If the user wants raw examples/records, use "rows".
- Respect year ranges if mentioned; otherwise leave them null.
- If user gives synonyms, normalize using this map: {SYNONYMS}
- Keep JSON small; do not include analysis, only fields below.

Allowed:
{json.dumps(guide, ensure_ascii=False)}

Output schema (one of these):
{{"intent":"pivot","dim1":"...", "dim2":"...", "metric":"...", "year_from":1400, "year_to":1404,"top_n":10}}
OR
{{"intent":"rows","filters":{{"Ø³ØªÙˆÙ†":"Ù…Ù‚Ø¯Ø§Ø±"}}, "limit": 200}}
""".strip()

            # 1) Ask GPT to generate the plan
            try:
                resp = client.chat_completion(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_q},
                    ],
                    temperature=0
                )
                plan_text = resp.choices[0].message["content"]
                plan = json.loads(plan_text)
            except Exception as e:
                plan = None
                st.chat_message("assistant").write(f"âš ï¸ GPT Ù†ØªÙˆØ§Ù†Ø³Øª Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø³Ø§Ø²Ø¯: {e}")

            # 2) Execute the plan if valid
            answer = None
            if plan:
                try:
                    intent = (plan.get("intent") or "").lower()

                    if intent == "pivot":
                        d1 = plan.get("dim1")
                        d2 = plan.get("dim2")
                        metric = plan.get("metric", "Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ")
                        y1 = plan.get("year_from")
                        y2 = plan.get("year_to")
                        top_n = int(plan.get("top_n") or 20)

                        # default year range
                        if not y1 or not y2:
                            try:
                                yr_min = sb.table(TABLE).select("Ø³Ø§Ù„").order("Ø³Ø§Ù„").limit(1).execute()
                                min_year = int(yr_min.data[0]["Ø³Ø§Ù„"]) if yr_min.data else 1300
                                yr_max = sb.table(TABLE).select("Ø³Ø§Ù„").order("Ø³Ø§Ù„", desc=True).limit(1).execute()
                                max_year = int(yr_max.data[0]["Ø³Ø§Ù„"]) if yr_max.data else 1500
                            except Exception:
                                min_year, max_year = 1300, 1500
                            y1 = int(y1) if y1 else min_year
                            y2 = int(y2) if y2 else max_year

                        # Run pivot RPC
                        res = sb.rpc(
                            "pivot_2d_numeric",
                            {"dim1": d1, "dim2": d2, "metric": metric, "year_from": int(y1), "year_to": int(y2)}
                        ).execute()

                        df_ans = pd.DataFrame(res.data or [])
                        if not df_ans.empty:
                            df_ans = df_ans.sort_values("total_value", ascending=False).head(top_n)
                            st.dataframe(df_ans, use_container_width=True)

                            # quick bar chart
                            parts = []
                            if "d1" in df_ans.columns:
                                parts.append(df_ans["d1"].astype(str))
                            if "d2" in df_ans.columns:
                                parts.append(df_ans["d2"].astype(str))
                            if parts:
                                label = parts[0].fillna("")
                                for s in parts[1:]:
                                    label = label.str.cat(s.fillna(""), sep=" â€” ")
                            else:
                                label = pd.Series([f"row {i+1}" for i in range(len(df_ans))])
                            chart_df = pd.DataFrame({"label": label, "total_value": df_ans["total_value"]}).sort_values("total_value", ascending=False)
                            st.bar_chart(chart_df.set_index("label")[["total_value"]])

                            answer = f"Pivot Â«{d1} Ã— {d2}Â» Ø±ÙˆÛŒ Â«{metric}Â» Ø¯Ø± Ø¨Ø§Ø²Ù‡Ù” {y1}â€“{y2} (Top {top_n})."
                        else:
                            answer = f"Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Pivot Â«{d1} Ã— {d2}Â» Ø±ÙˆÛŒ Â«{metric}Â» Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

                    elif intent == "rows":
                        filters = plan.get("filters") or {}
                        limit = int(plan.get("limit") or 200)

                        q = sb.table(TABLE).select("*")
                        for col, val in filters.items():
                            col = SYNONYMS.get(col, col)
                            if col not in ALLOWED_DIMS:
                                continue
                            if isinstance(val, list):
                                q = q.in_(col, val)
                            else:
                                q = q.eq(col, val)
                        q = q.limit(limit)

                        res = q.execute()
                        df_ans = pd.DataFrame(res.data or [])
                        if not df_ans.empty:
                            st.dataframe(df_ans, use_container_width=True)
                            answer = f"{len(df_ans)} Ø±Ø¯ÛŒÙ Ù…Ø·Ø§Ø¨Ù‚ ÙÛŒÙ„ØªØ±Ù‡Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ (Ø­Ø¯Ø§Ú©Ø«Ø± {limit})."
                        else:
                            answer = "Ø±Ø¯ÛŒÙÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø´Ø±Ø§ÛŒØ· Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

                    else:
                        answer = "Ø¬Ù‡Øª Ù¾Ø§Ø³Ø® Ù†ÛŒØ§Ø² Ø§Ø³Øª Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯ Pivot Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÛŒØ§ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…."

                except Exception as e:
                    answer = f"âš ï¸ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯: {e}"

            # Always show assistant message
            if not answer:
                answer = "Ø³ÙˆØ§Ù„ Ø±Ø§ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ø¨Ù¾Ø±Ø³ ÛŒØ§ Ù…Ø«Ø§Ù„ Ø¨Ø¯Ù‡ ØªØ§ Pivot ÛŒØ§ ÙÛŒÙ„ØªØ± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø³Ø§Ø²Ù…."

            st.chat_message("assistant").write(answer)
            st.session_state.data_chat.append({"role": "assistant", "content": answer})
